{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ddf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS sent: SID SM73fffe2536b9aeba61d43734ca332fa6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import winsound\n",
    "import os\n",
    "from scipy.spatial import distance as dist\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "EAR_THRESHOLD = 0.21\n",
    "MAR_THRESHOLD = 0.75\n",
    "DROWSINESS_SCORE_THRESHOLD = 3\n",
    "ALARM_DURATION = 1500\n",
    "FRAME_SKIP = 2\n",
    "EAR_HISTORY_LENGTH = 10\n",
    "MIN_FACE_SIZE = 300\n",
    "ALARM_COOLDOWN = 3\n",
    "folder_path = r\"C:\\Users\\User\\Desktop\\deep learn\\drosiness image\"\n",
    "\n",
    "# Initialize variables\n",
    "drowsiness_score = 0\n",
    "alarm_triggered = False\n",
    "frame_counter = 0\n",
    "ear_history = deque(maxlen=EAR_HISTORY_LENGTH)\n",
    "last_alarm_time = 0\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    ear_history.append(ear)\n",
    "    return ear\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[2], mouth[10])\n",
    "    B = dist.euclidean(mouth[4], mouth[8])\n",
    "    C = dist.euclidean(mouth[3], mouth[9])\n",
    "    D = dist.euclidean(mouth[0], mouth[6])\n",
    "    mar = (A + B + C) / (3.0 * D)\n",
    "    return mar\n",
    "\n",
    "def get_smoothed_ear():\n",
    "    return np.mean(ear_history) if ear_history else 0\n",
    "\n",
    "def calculate_face_size(face_location):\n",
    "    top, right, bottom, left = face_location\n",
    "    return (bottom - top) * (right - left)\n",
    "\n",
    "def update_drowsiness_score(avg_ear, mar, face_size, brightness):\n",
    "    global drowsiness_score, alarm_triggered, last_alarm_time\n",
    "    \n",
    "    size_factor = max(0.8, min(1.2, face_size / MIN_FACE_SIZE))\n",
    "    brightness_factor = max(0.8, min(1.2, brightness / 127))\n",
    "\n",
    "    adjusted_ear_thresh = EAR_THRESHOLD * size_factor * brightness_factor\n",
    "    adjusted_mar_thresh = MAR_THRESHOLD * size_factor * (2 - brightness_factor)\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    if avg_ear < adjusted_ear_thresh or mar > adjusted_mar_thresh:\n",
    "        increment = 3 if avg_ear < adjusted_ear_thresh * 0.8 else 1\n",
    "        drowsiness_score = min(drowsiness_score + increment, DROWSINESS_SCORE_THRESHOLD * 2)\n",
    "    else:\n",
    "        drowsiness_score = max(drowsiness_score - 1, 0)\n",
    "\n",
    "    if (drowsiness_score >= DROWSINESS_SCORE_THRESHOLD and \n",
    "        not alarm_triggered and \n",
    "        current_time - last_alarm_time > ALARM_COOLDOWN):\n",
    "        winsound.Beep(1500, ALARM_DURATION)\n",
    "        alarm_triggered = True\n",
    "        last_alarm_time = current_time\n",
    "    elif drowsiness_score < DROWSINESS_SCORE_THRESHOLD // 2:\n",
    "        alarm_triggered = False\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_counter += 1\n",
    "    if frame_counter % FRAME_SKIP != 0:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    brightness = np.mean(gray_frame)\n",
    "\n",
    "    face_locations = face_recognition.face_locations(rgb_frame, model=\"hog\")\n",
    "    landmarks = face_recognition.face_landmarks(rgb_frame, face_locations)\n",
    "\n",
    "    if landmarks:\n",
    "        for face_loc, landmark in zip(face_locations, landmarks):\n",
    "            try:\n",
    "                left_eye = landmark[\"left_eye\"]\n",
    "                right_eye = landmark[\"right_eye\"]\n",
    "                mouth = landmark[\"top_lip\"] + landmark[\"bottom_lip\"]\n",
    "                face_size = calculate_face_size(face_loc)\n",
    "\n",
    "                left_ear = eye_aspect_ratio(left_eye)\n",
    "                right_ear = eye_aspect_ratio(right_eye)\n",
    "                avg_ear = (left_ear + right_ear) / 2.0\n",
    "                smoothed_ear = get_smoothed_ear()\n",
    "                mar = mouth_aspect_ratio(mouth)\n",
    "\n",
    "                update_drowsiness_score(smoothed_ear, mar, face_size, brightness)\n",
    "\n",
    "                for point in left_eye + right_eye:\n",
    "                    cv2.circle(frame, point, 2, (0, 255, 255), -1)\n",
    "                for point in mouth:\n",
    "                    cv2.circle(frame, point, 1, (255, 0, 0), -1)\n",
    "\n",
    "                status = \"AWAKE\" if drowsiness_score == 0 else \\\n",
    "                         \"WARNING\" if drowsiness_score < DROWSINESS_SCORE_THRESHOLD else \\\n",
    "                         \"DROWSY!\"\n",
    "                color = (0, 255, 0) if status == \"AWAKE\" else \\\n",
    "                        (0, 165, 255) if status == \"WARNING\" else \\\n",
    "                        (0, 0, 255)\n",
    "\n",
    "                cv2.putText(frame, f\"Status: {status}\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2)\n",
    "                cv2.putText(frame, f\"EAR: {smoothed_ear:.2f} (Thresh: {EAR_THRESHOLD:.2f})\", (10, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)\n",
    "                cv2.putText(frame, f\"MAR: {mar:.2f} (Thresh: {MAR_THRESHOLD:.2f})\", (10, 85),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)\n",
    "                cv2.putText(frame, f\"Score: {drowsiness_score}/{DROWSINESS_SCORE_THRESHOLD}\", (10, 110),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                if alarm_triggered:\n",
    "                    cv2.putText(frame, \"ALERT! DROWSINESS DETECTED!\", (150, 50),\n",
    "                                cv2.FONT_HERSHEY_TRIPLEX, 0.9, (0, 0, 255), 2)\n",
    "                    cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 10)\n",
    "                    filename = f\"drowsy_alert_{int(time.time())}.jpg\"\n",
    "                    full_path = os.path.join(folder_path, filename)\n",
    "                    cv2.imwrite(full_path, frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Processing error: {e}\")\n",
    "    else:\n",
    "        cv2.putText(frame, \"NO FACE DETECTED\", (250, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        drowsiness_score = max(drowsiness_score - 1, 0)\n",
    "\n",
    "    cv2.imshow(\"Enhanced Drowsiness Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
